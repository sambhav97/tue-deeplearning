{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "557bc264",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/assignments/assignment_1/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4ec9a11-3515-40aa-97ac-73c249df560e",
   "metadata": {
    "id": "a4ec9a11-3515-40aa-97ac-73c249df560e"
   },
   "source": [
    "# Group Number: 12\n",
    "# Student 1: Denise La Gordt Dillie\n",
    "# Student 2: Andreea Maican\n",
    "# Student 3: Sambhav Jain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8c200a7-b3ab-4c9a-bcf8-320271c040f3",
   "metadata": {
    "id": "a8c200a7-b3ab-4c9a-bcf8-320271c040f3"
   },
   "source": [
    "In case you are using google colab, uncomment the following cell, and modify the ```notebook_dir``` variable to contain the directory this notebook is in. It will automatically download the .py files needed for this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "igFRsZKIC18S",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:56:26.426258Z",
     "start_time": "2023-05-30T11:56:26.421997Z"
    },
    "id": "igFRsZKIC18S"
   },
   "outputs": [],
   "source": [
    "# # Change the following  line to the directory this notebook is (if using colab)\n",
    "# # In case you do not know the path, open the file navigator on the left in colab\n",
    "# # Find the folder containing this notebook, then press on the three dots --> copy path\n",
    "# notebook_dir = \"/content/drive/MyDrive/Colab Notebooks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828246d4-75b2-42b7-ab06-925e6624f411",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:56:35.801096Z",
     "start_time": "2023-05-30T11:56:35.788433Z"
    },
    "id": "828246d4-75b2-42b7-ab06-925e6624f411"
   },
   "outputs": [],
   "source": [
    "# # UNCOMMENT IF USING COLAB\n",
    "# from google.colab import drive\n",
    "# import requests\n",
    "# drive.mount('/content/drive')\n",
    "# import sys\n",
    "# import os\n",
    "# sys.path.insert(0, notebook_dir) \n",
    "# os.chdir(notebook_dir)\n",
    "# symco = \"https://github.com/vlamen/tue-deeplearning/blob/main/assignments/assignment_1/symconv.py?raw=true\"\n",
    "# crpt = \"https://github.com/vlamen/tue-deeplearning/blob/main/assignments/assignment_1/carpet.py?raw=true\"\n",
    "# r_s = requests.get(symco, allow_redirects=True)\n",
    "# r_c = requests.get(crpt, allow_redirects=True)\n",
    "# with open('symconv.py', 'wb') as f:\n",
    "#     f.write(r_s.content)\n",
    "# with open('carpet.py', 'wb') as f:\n",
    "#     f.write(r_c.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c401bd6-3828-4f5e-ada8-a026e0a167bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:56:37.850901Z",
     "start_time": "2023-05-30T11:56:36.680802Z"
    },
    "id": "1c401bd6-3828-4f5e-ada8-a026e0a167bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\.virtualenvs\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "import io\n",
    "import requests\n",
    "\n",
    "import symconv as sc\n",
    "from carpet import show_carpet, oh_to_label\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35c0bcb8-5215-40b3-8ba2-7e4208651c90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:56:39.232122Z",
     "start_time": "2023-05-30T11:56:39.221646Z"
    },
    "id": "35c0bcb8-5215-40b3-8ba2-7e4208651c90"
   },
   "outputs": [],
   "source": [
    "def load_numpy_arr_from_url(url):\n",
    "    \"\"\"\n",
    "    Loads a numpy array from surfdrive. \n",
    "    \n",
    "    Input:\n",
    "    url: Download link of dataset \n",
    "    \n",
    "    Outputs:\n",
    "    dataset: numpy array with input features or labels\n",
    "    \"\"\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    return np.load(io.BytesIO(response.content)) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "045a1fdc-8c84-4829-b8c8-14c957f733f6",
   "metadata": {
    "id": "045a1fdc-8c84-4829-b8c8-14c957f733f6"
   },
   "source": [
    "# Task 1: Pattern Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45b63ab-610e-4e03-b1da-a717c2a77c8a",
   "metadata": {
    "id": "a45b63ab-610e-4e03-b1da-a717c2a77c8a"
   },
   "outputs": [],
   "source": [
    "# loading training and testing data for task 1\n",
    "# DO NOT MODIFY\n",
    "task1 = load_numpy_arr_from_url(\"https://github.com/vlamen/tue-deeplearning/blob/main/assignments/assignment_1/task1data.npz?raw=true\")\n",
    "# task1 = np.load(\"task1data.npz\")\n",
    "\n",
    "X = torch.tensor(task1['arr_0']).float()\n",
    "y = torch.tensor(task1['arr_1']).float()\n",
    "\n",
    "X_train = X[:7500]\n",
    "X_val = X[7500:9500]\n",
    "X_test = X[9500:]\n",
    "y_train = y[:7500]\n",
    "y_val = y[7500:9500]\n",
    "y_test  = y[9500:]\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "\n",
    "print(f\"Carpet train shape: {X_train.shape}\")\n",
    "print(f\"Label train shape: {y_train.shape}\")\n",
    "print(f\"Carpet validation shape: {X_val.shape}\")\n",
    "print(f\"Label validation shape: {y_val.shape}\")\n",
    "print(f\"Carpet test shape: {X_test.shape}\")\n",
    "print(f\"Label test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c5553f-023f-48fc-81b5-83184a46a21d",
   "metadata": {
    "id": "a4c5553f-023f-48fc-81b5-83184a46a21d"
   },
   "outputs": [],
   "source": [
    "# random carpet\n",
    "idx = np.random.randint(0,7500)\n",
    "show_carpet(X_train, idx)\n",
    "print('Carpet from', oh_to_label(y_train[idx,None])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, optimizer=None):\n",
    "    yb = torch.argmax(yb, dim=1)\n",
    "\n",
    "    assert yb.dim() <= 1, \"Target tensor must have 0 or 1 dimensions\"\n",
    "    assert yb.numel() == len(xb), \"Target tensor size must match input size\"\n",
    "\n",
    "    output = model(xb)\n",
    "    loss = loss_func(output, yb.long())\n",
    "\n",
    "    if optimizer is not None:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    _, preds = torch.max(output, 1)\n",
    "    corrects = torch.sum(preds == yb.long())\n",
    "\n",
    "    return loss.item(), corrects, len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def fit(epochs, model, loss_func, optimizer, train_dl, valid_dl, test_dl):\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Training process\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        sample_num = 0\n",
    "\n",
    "        for xb, yb in train_dl:\n",
    "            losses, corrects, nums = loss_batch(model, loss_func, xb, yb, optimizer)\n",
    "            running_loss += losses * xb.size(0)\n",
    "            running_corrects += corrects\n",
    "            sample_num += nums\n",
    "\n",
    "        train_loss = running_loss / sample_num\n",
    "        train_acc = running_corrects.double() / sample_num\n",
    "\n",
    "        # Validation process\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            sample_num = 0\n",
    "\n",
    "            for xb, yb in valid_dl:\n",
    "                losses, corrects, nums = loss_batch(model, loss_func, xb, yb)\n",
    "                running_loss += losses * xb.size(0)\n",
    "                running_corrects += corrects\n",
    "                sample_num += nums\n",
    "\n",
    "            val_loss = running_loss / sample_num\n",
    "            val_acc = running_corrects.double() / sample_num\n",
    "\n",
    "        # Testing process\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            sample_num = 0\n",
    "\n",
    "            for xb, yb in test_dl:\n",
    "                losses, corrects, nums = loss_batch(model, loss_func, xb, yb)\n",
    "                running_loss += losses * xb.size(0)\n",
    "                running_corrects += corrects\n",
    "                sample_num += nums\n",
    "\n",
    "            test_loss = running_loss / sample_num\n",
    "            test_acc = running_corrects.double() / sample_num\n",
    "\n",
    "        # Print the results\n",
    "        print(f'EPOCH: {epoch+1:0>{len(str(epochs))}}/{epochs}', end=' ')\n",
    "        print(f'LOSS: {train_loss:.4f}', f'ACC: {train_acc:.4f} ', end=' ')\n",
    "        print(f'VAL-LOSS: {val_loss:.4f}', f'VAL-ACC: {val_acc:.4f} ', end=' ')\n",
    "        print(f'TEST-LOSS: {test_loss:.4f}', f'TEST-ACC: {test_acc:.4f} ', end='\\n')\n",
    "\n",
    "        # Save losses and accuracies\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "\n",
    "    # Plot losses and accuracies\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, epochs+1), train_losses, 'r:', label='Train Loss')\n",
    "    plt.plot(range(1, epochs+1), val_losses, 'g:', label='Validation Loss')\n",
    "    plt.plot(range(1, epochs+1), test_losses, 'b:', label='Test Loss')\n",
    "    plt.plot(range(1, epochs+1), train_accs, 'r', label='Train Accuracy')\n",
    "    plt.plot(range(1, epochs+1), val_accs, 'g', label='Validation Accuracy')\n",
    "    plt.plot(range(1, epochs+1), test_accs, 'b', label='Test Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss / Accuracy')\n",
    "    plt.title('Loss and Accuracy vs. Epochs')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, batch_size):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=batch_size, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=batch_size * 2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dl, valid_dl = get_data(train_dataset, val_dataset, batch_size)\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(1, 32, kernel_size=4, stride=4, rotation=4, reflection=False),\n",
    "    nn.ReLU(inplace=True),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Conv2d(32, 64, kernel_size=3, stride=3),\n",
    "    nn.ReLU(inplace=True),\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(64, 10, kernel_size=5, stride=1, rotation=4, reflection=False),\n",
    "    nn.ReLU(inplace=True),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(10),\n",
    "    nn.Dropout(0.2),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    "    nn.Linear(40, 100),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(100, 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "lr = 0.06\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "epochs = 20\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "fit(epochs, model, loss_func, optimizer, train_dl, valid_dl, test_dl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06c5a8d4",
   "metadata": {},
   "source": [
    "## Task 1: Question 5d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Experiment 1\n",
    "In this experiment, we change the number of convolutional filters in the model architecture. Convolutional filters are responsible for capturing different patterns and features from the input data. By altering the number of filters, we can assess the effect on the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Experiment 1: Change the Number of Convolutional Filters\n",
    "model_exp1 = nn.Sequential(\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(1, 16, kernel_size=4, stride=4, rotation=4, reflection=False), # Change the number of filters to 16\n",
    "    nn.ReLU(inplace=True),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(16), # Adjust the batch normalization layer accordingly\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Conv2d(16, 64, kernel_size=3, stride=3),\n",
    "    nn.ReLU(inplace=True),\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(64, 10, kernel_size=5, stride=1, rotation=4, reflection=False),\n",
    "    nn.ReLU(inplace=True),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(10),\n",
    "    nn.Dropout(0.2),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    "    nn.Linear(40, 100),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(100, 3),\n",
    ")\n",
    "\n",
    "optimizer_exp1 = optim.SGD(model_exp1.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model_exp1, loss_func, optimizer_exp1, train_dl, valid_dl, test_dl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Experiment 2\n",
    "In this experiment, we change the activation function used in the model architecture. The activation function introduces non-linearity to the model, allowing it to learn complex patterns and make non-linear predictions. By altering the activation function, we can assess its effect on the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e8735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2: Change Activation Function\n",
    "model_exp2 = nn.Sequential(\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(1, 32, kernel_size=4, stride=4, rotation=4, reflection=False),\n",
    "    nn.LeakyReLU(inplace=True),  # Change activation function\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Conv2d(32, 64, kernel_size=3, stride=3),\n",
    "    nn.LeakyReLU(inplace=True),  # Change activation function\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(64, 10, kernel_size=5, stride=1, rotation=4, reflection=False),\n",
    "    nn.LeakyReLU(inplace=True),  # Change activation function\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(10),\n",
    "    nn.Dropout(0.2),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    "    nn.Linear(40, 100),\n",
    "    nn.LeakyReLU(inplace=True),  # Change activation function\n",
    "    nn.Linear(100, 3),\n",
    ")\n",
    "\n",
    "optimizer_exp2 = optim.SGD(model_exp2.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model_exp2, loss_func, optimizer_exp2, train_dl, valid_dl, test_dl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Experiment 3\n",
    "In this experiment, we change the learning rate used for training the model. The learning rate determines the step size at which the model updates its parameters during the optimization process. By adjusting the learning rate, we can explore its effect on the convergence speed and the overall performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Experiment 3: Adjust Learning Rate\n",
    "lr_exp3 = 0.01  # Change learning rate\n",
    "\n",
    "model_exp3 = nn.Sequential(\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(1, 32, kernel_size=4, stride=4, rotation=4, reflection=False),\n",
    "    nn.ReLU(inplace=True),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Conv2d(32, 64, kernel_size=3, stride=3),\n",
    "    nn.ReLU(inplace=True),\n",
    "    sc.Slice(rotation=4, reflection=False),\n",
    "    sc.SymmetryConv2d(64, 10, kernel_size=5, stride=1, rotation=4, reflection=False),\n",
    "    nn.ReLU(inplace=True),\n",
    "    sc.SymmetryPool(),\n",
    "    nn.BatchNorm2d(10),\n",
    "    nn.Dropout(0.2),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    "    nn.Linear(40, 100),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(100, 3),\n",
    ")\n",
    "\n",
    "optimizer_exp3 = optim.SGD(model_exp3.parameters(), lr=lr_exp3, momentum=0.9)\n",
    "\n",
    "fit(epochs, model_exp3, loss_func, optimizer_exp3, train_dl, valid_dl, test_dl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e988bc2-6ba1-49cd-ae26-6feea8ad2776",
   "metadata": {
    "id": "1e988bc2-6ba1-49cd-ae26-6feea8ad2776"
   },
   "source": [
    "# Task 2: Carpet Matching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20a2ce3a-4c8c-4f1f-9a29-113063ce7f74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:56:44.915631Z",
     "start_time": "2023-05-30T11:56:43.761739Z"
    },
    "id": "20a2ce3a-4c8c-4f1f-9a29-113063ce7f74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpet train shape: (15000, 1, 96, 60)\n",
      "Label train shape: (15000,)\n",
      "Ground truth test shape: (300,)\n",
      "Query carpets shape: (300, 1, 96, 60)\n",
      "Candidate carpets shape: (300, 4, 1, 96, 60)\n"
     ]
    }
   ],
   "source": [
    "# loading training and testing data for task 2\n",
    "# DO NOT MODIFY\n",
    "task2 = load_numpy_arr_from_url(\"https://github.com/vlamen/tue-deeplearning/blob/main/assignments/assignment_1/task2data.npz?raw=true\")\n",
    "\n",
    "X = task2['arr_0'].astype(float)\n",
    "y = task2['arr_1'].astype(float)\n",
    "gt = task2['arr_2'].astype(float) # ground truth\n",
    "queries = task2['arr_3'].astype(float)\n",
    "targets = task2['arr_4'].astype(float)\n",
    "\n",
    "print(f\"Carpet train shape: {X.shape}\")\n",
    "print(f\"Label train shape: {y.shape}\")\n",
    "print(f\"Ground truth test shape: {gt.shape}\")\n",
    "print(f\"Query carpets shape: {queries.shape}\")\n",
    "print(f\"Candidate carpets shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50179340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import BatchSampler\n",
    "import numpy as np\n",
    "class BalancedBatchSampler(BatchSampler):\n",
    "    \"\"\"\n",
    "    Returns batches of size n_classes * n_samples\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, labels, n_classes, n_samples):\n",
    "        self.labels = labels\n",
    "        self.labels_set = list(set(self.labels))\n",
    "        self.label_to_indices = {label: np.where(  np.array(self.labels) == label)[0]\n",
    "                                 for label in self.labels_set}\n",
    "        for l in self.labels_set:\n",
    "            np.random.shuffle(self.label_to_indices[l])\n",
    "        self.used_label_indices_count = {label: 0 for label in self.labels_set}\n",
    "        self.count = 0\n",
    "        self.n_classes = n_classes\n",
    "        self.n_samples = n_samples\n",
    "        self.n_dataset = len(self.labels)\n",
    "        self.batch_size = self.n_samples * self.n_classes\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.count = 0\n",
    "        while self.count + self.batch_size < self.n_dataset:\n",
    "            classes = np.random.choice(self.labels_set, self.n_classes, replace=False)\n",
    "            indices = []\n",
    "            for class_ in classes:\n",
    "                indices.extend(self.label_to_indices[class_][\n",
    "                               self.used_label_indices_count[class_]:self.used_label_indices_count[\n",
    "                                                                         class_] + self.n_samples])\n",
    "                self.used_label_indices_count[class_] += self.n_samples\n",
    "                if self.used_label_indices_count[class_] + self.n_samples > len(self.label_to_indices[class_]):\n",
    "                    np.random.shuffle(self.label_to_indices[class_])\n",
    "                    self.used_label_indices_count[class_] = 0\n",
    "            yield indices\n",
    "            self.count += self.n_classes * self.n_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_dataset // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc9ef54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNet_Sym(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"CNN Builder.\"\"\"\n",
    "        super(EmbeddingNet_Sym, self).__init__()\n",
    "\n",
    "        self.front_layer = nn.Sequential(\n",
    "                sc.Slice(rotation=4, reflection=False),\n",
    "                sc.SymmetryConv2d(1, 32, kernel_size=4, stride=4, rotation=4, reflection=False),\n",
    "                nn.ReLU(inplace=True),\n",
    "                sc.SymmetryPool(),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Conv2d(32, 64, kernel_size=3, stride=3),\n",
    "                nn.ReLU(inplace=True),\n",
    "                sc.Slice(rotation=4, reflection=False),\n",
    "                sc.SymmetryConv2d(64, 10, kernel_size=5, stride=1, rotation=4, reflection=False),\n",
    "                nn.ReLU(inplace=True),\n",
    "                sc.SymmetryPool(),\n",
    "                nn.BatchNorm2d(10),\n",
    "                nn.Dropout(0.2),\n",
    "                Lambda(lambda x: x.view(x.size(0), -1)),\n",
    "                nn.Linear(40, 100),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "\n",
    "        self.last_layer = nn.Linear(100, 200)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward.\"\"\"\n",
    "        # conv layers\n",
    "        x = self.front_layer(x)\n",
    "        x = self.last_layer(x)\n",
    "        return x\n",
    "    \n",
    "    def get_embedding(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b08fc08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.X[index]\n",
    "        label = self.y[index]\n",
    "\n",
    "        # Convert the image and label to torch tensors\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "dataset = CustomDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69052f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200  # Number of classes in each mini-batch\n",
    "m = 5   # Number of samples from each class\n",
    "\n",
    "train_batch_sampler = BalancedBatchSampler(y, n_classes=N, n_samples=m)\n",
    "\n",
    "triplets_train_loader = torch.utils.data.DataLoader(dataset, batch_sampler=train_batch_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f10b027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def pdist(vectors):\n",
    "    distance_matrix = -2 * vectors.mm(torch.t(vectors)) + vectors.pow(2).sum(dim=1).view(1, -1) + vectors.pow(2).sum(\n",
    "        dim=1).view(-1, 1)\n",
    "    return distance_matrix\n",
    "\n",
    "class Informative_Negative_TripletSelector():\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        super(Informative_Negative_TripletSelector, self).__init__()\n",
    "  \n",
    "        self.margin = margin\n",
    "  \n",
    "   # Our goal is to mining informative triplets.\n",
    "    def informative_negative(self, loss_values):\n",
    "        \n",
    "        informative_negative = np.where(loss_values > 0)[0]\n",
    "        return np.random.choice(informative_negative) if len(informative_negative) > 0 else None\n",
    "    \n",
    "\n",
    "    def get_triplets(self, embeddings, labels):\n",
    "        \n",
    "        if torch.cuda.is_available()==False:\n",
    "            embeddings = embeddings.cpu()\n",
    "        distance_matrix = pdist(embeddings)\n",
    "        distance_matrix = distance_matrix.cpu()\n",
    "\n",
    "        labels = labels.cpu().data.numpy()\n",
    "        triplets = []\n",
    "\n",
    "        for label in set(labels):\n",
    "            label_mask = (labels == label)\n",
    "            label_indices = np.where(label_mask)[0]\n",
    "            if len(label_indices) < 2:\n",
    "                continue\n",
    "            negative_indices = np.where(np.logical_not(label_mask))[0]\n",
    "            anchor_positives = list(combinations(label_indices, 2))  # All anchor-positive pairs\n",
    "            anchor_positives = np.array(anchor_positives)\n",
    "\n",
    "            \n",
    "            ap_distances = distance_matrix[anchor_positives[:, 0], anchor_positives[:, 1]]\n",
    "            for anchor_positive, ap_distance in zip(anchor_positives, ap_distances):\n",
    "                loss_values = ap_distance - distance_matrix[torch.LongTensor(np.array([anchor_positive[0]])), torch.LongTensor(negative_indices)] + self.margin\n",
    "                loss_values = loss_values.data.cpu().numpy()\n",
    "                \n",
    "                hard_negative = self.informative_negative(loss_values)\n",
    "                if hard_negative is not None:\n",
    "                    hard_negative = negative_indices[hard_negative]\n",
    "                    triplets.append([anchor_positive[0], anchor_positive[1], hard_negative])\n",
    "\n",
    "        if len(triplets) == 0:\n",
    "            triplets.append([anchor_positive[0], anchor_positive[1], negative_indices[0]])\n",
    "\n",
    "        triplets = np.array(triplets)\n",
    "        \n",
    "        return torch.LongTensor(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01599cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Triplets loss\n",
    "    Takes a batch of embeddings and corresponding labels.\n",
    "    Triplets are generated using triplet_selector object that take embeddings and targets and return indices of\n",
    "    triplets\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin, triplet_selector):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.triplet_selector = triplet_selector\n",
    "\n",
    "    def forward(self, embeddings, target):\n",
    "\n",
    "        triplets = self.triplet_selector.get_triplets(embeddings, target)\n",
    "\n",
    "        if embeddings.is_cuda:\n",
    "            triplets = triplets.cuda()\n",
    "\n",
    "            \n",
    "        anchor_idx= triplets[:, 0]  \n",
    "        positive_idx= triplets[:, 1]  \n",
    "        negative_idx= triplets[:, 2]  \n",
    "            \n",
    "            \n",
    "        ap_distances = (embeddings[anchor_idx] - embeddings[positive_idx]).pow(2).sum(1)  # .pow(.5)\n",
    "        an_distances = (embeddings[anchor_idx] - embeddings[negative_idx]).pow(2).sum(1)  # .pow(.5)\n",
    "        losses = F.relu(ap_distances - an_distances + self.margin)\n",
    "\n",
    "        return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088abfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def query_performance(model, queries, targets, gt, top=1):\n",
    "    assert top >= 1\n",
    "    cnt = 0\n",
    "\n",
    "    queries_np = queries\n",
    "    targets_np = targets\n",
    "\n",
    "\n",
    "    for i in range(gt.shape[0]):\n",
    "        q = torch.from_numpy(queries_np[i][None]).float().to(device)\n",
    "        t = torch.from_numpy(targets_np[i]).float().to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            emb_q = model.get_embedding(q).cpu().numpy()  \n",
    "            emb_t = model.get_embedding(t).cpu().numpy()  \n",
    "        \n",
    "            dists = pairwise_distances(emb_q, emb_t)\n",
    "\n",
    "            if top == 1:\n",
    "                pred = np.argmin(dists)\n",
    "                if pred == gt[i]:\n",
    "                    cnt += 1\n",
    "            else:\n",
    "                pred = np.argsort(dists)\n",
    "                if gt[i] in pred[0, :top].tolist():\n",
    "                    cnt += 1\n",
    "\n",
    "    return 100 * cnt / gt.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "630a6f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self,\n",
    "                 model: torch.nn.Module,\n",
    "                 device: torch.device,\n",
    "                 criterion: torch.nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 training_DataLoader: torch.utils.data.Dataset,\n",
    "                 epochs: int\n",
    "                 ):\n",
    "        \n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.training_DataLoader = training_DataLoader\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def run_trainer(self):\n",
    "\n",
    "        top_1_accuracies = []\n",
    "        top_2_accuracies = []\n",
    "        top_3_accuracies = []\n",
    "        train_losses_mean = []\n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "                 \n",
    "            self.model.train()  # train mode\n",
    "\n",
    "            train_losses=[]\n",
    "            for batch in self.training_DataLoader:\n",
    "\n",
    "                x,y=batch\n",
    "                input, target = x.to(self.device), y.to(self.device)  # send to device (GPU or CPU)\n",
    "                self.optimizer.zero_grad()  # zerograd the parameters\n",
    "                out = self.model(input)  # one forward pass\n",
    "                loss = self.criterion(out, target)  # calculate loss\n",
    "                 \n",
    "                loss_value = loss.item()\n",
    "                train_losses.append(loss_value)\n",
    "                 \n",
    "                loss.backward()  # one backward pass\n",
    "                self.optimizer.step()  # update the parameters\n",
    "                \n",
    "            self.model.eval()\n",
    "            top_1_accuracy = query_performance(self.model, queries, targets, gt, top=1)\n",
    "            top_2_accuracy = query_performance(self.model, queries, targets, gt, top=2)\n",
    "            top_3_accuracy = query_performance(self.model, queries, targets, gt, top=3)\n",
    "            \n",
    "            top_1_accuracies.append(top_1_accuracy)\n",
    "            top_2_accuracies.append(top_2_accuracy)\n",
    "            top_3_accuracies.append(top_3_accuracy)\n",
    "            \n",
    "            train_losses_mean.append(np.mean(train_losses))\n",
    "                \n",
    "            # print the results\n",
    "            print(\n",
    "                f'EPOCH: {epoch+1:0>{len(str(self.epochs))}}/{self.epochs}',\n",
    "                end=' '\n",
    "            )\n",
    "            print(f'LOSS: {np.mean(train_losses):.4f}',end=' ')\n",
    "            print(f'top-1 accuracy: {top_1_accuracy:.2f}%')\n",
    "        \n",
    "        # Plot losses and accuracies\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(range(1, self.epochs+1), train_losses_mean, 'r:', label='Train Loss')\n",
    "        plt.plot(range(1, self.epochs+1), [val/100 for val in top_1_accuracies], 'b', label='Top 1 Accuracy')\n",
    "        plt.plot(range(1, self.epochs+1), [val/100 for val in top_2_accuracies], 'b', label='Top 2 Accuracy')\n",
    "        plt.plot(range(1, self.epochs+1), [val/100 for val in top_3_accuracies], 'b', label='Top 3 Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss / Accuracy')\n",
    "        plt.title('Loss and Accuracy vs. Epochs')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0820039b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [01:34<06:18, 94.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1/5 LOSS: 4.5926 top-1 accuracy: 32.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [03:09<04:44, 94.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 2/5 LOSS: 4.4210 top-1 accuracy: 33.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [04:44<03:09, 94.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 3/5 LOSS: 4.1589 top-1 accuracy: 35.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [06:16<01:33, 93.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 4/5 LOSS: 4.0029 top-1 accuracy: 39.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [07:51<00:00, 94.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 5/5 LOSS: 3.8071 top-1 accuracy: 43.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "    \n",
    "# model\n",
    "embedding_net_sym = EmbeddingNet_Sym()\n",
    "model_sym = embedding_net_sym.to(device)\n",
    "\n",
    "# margin value\n",
    "margin=1\n",
    "\n",
    "# criterion\n",
    "criterion_sym = TripletLoss(margin, Informative_Negative_TripletSelector(margin))\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model_sym.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(model=model_sym,\n",
    "                  device=device,\n",
    "                  criterion=criterion_sym,\n",
    "                  optimizer=optimizer,\n",
    "                  training_DataLoader=triplets_train_loader,\n",
    "                  epochs=5)\n",
    "\n",
    "# start training\n",
    "trainer.run_trainer()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
