{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d32f8d18",
   "metadata": {},
   "source": [
    "# Group Details\n",
    "\n",
    "## Group Name: 12\n",
    "\n",
    "### Student 1: Denise La Gordt Dillie\n",
    "\n",
    "### Student 2: Andreea Maican\n",
    "\n",
    "### Student 3: Sambhav Jain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "faec2056",
   "metadata": {},
   "source": [
    "# Loading Data and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d0580a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0756591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(filename, task):\n",
    "    datapoint = np.load(filename)\n",
    "    if task == 'task 1':\n",
    "        initial_state = datapoint['initial_state']\n",
    "        terminal_state = datapoint['terminal_state']\n",
    "        return initial_state, terminal_state\n",
    "    elif task == 'task 2' or task == 'task 3':\n",
    "        whole_trajectory = datapoint['trajectory']\n",
    "        # change shape: (num_bodies, attributes, time) ->  num_bodies, time, attributes\n",
    "        whole_trajectory = np.swapaxes(whole_trajectory, 1, 2)\n",
    "        initial_state = whole_trajectory[:, 0]\n",
    "        target = whole_trajectory[:, 1:, 1:]  # drop the first timepoint (second dim) and mass (last dim) for the prediction task\n",
    "        return initial_state, target\n",
    "    else:\n",
    "        raise NotImplementedError(\"'task' argument should be 'task 1', 'task 2' or 'task 3'!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb77a4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of initial state (model input): (8, 5)\n",
      "[[ 4.54673709 -5.27118739  5.07863417 -1.09690628 -3.66929964]\n",
      " [ 3.57509525  4.3270607  -0.08095022 -0.57868726 -2.95971243]\n",
      " [ 2.67733735 -5.15972108  5.35238208  2.42652043  1.45870728]\n",
      " [ 2.27455417 -6.79584511  2.29632123  0.30418238 -0.4065998 ]\n",
      " [ 2.38359341 -2.75861066  1.77940931 -0.07643627 -0.35954359]\n",
      " [ 4.28596268  0.34981219  4.8286224   1.35630962 -2.55760522]\n",
      " [ 3.03118516 -0.50562258 15.04631712 -0.94772523 14.98127867]\n",
      " [ 4.13530017  1.81342682  3.84375499 -0.6989711  -2.25092411]]\n",
      "shape of terminal state (to be predicted by model): (8, 2)\n",
      "The initial x-coordinate of the body with index 2 in this trajectory was -5.159721083543527\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell gives an example of loading a datapoint with numpy for task 1.\n",
    "\n",
    "The arrays returned by the function are structures as follows:\n",
    "initial_state: shape (n_bodies, [mass, x, y, v_x, v_y])\n",
    "terminal_state: shape (n_bodies, [x, y])\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "example = load_array('C:/Users/Gebruiker/OneDrive - TU Eindhoven/TUe/Master/2AMM10/tue-deeplearning/assignments/assignment_2/data/task 1/train/trajectory_0.npz', task='task 1')\n",
    "\n",
    "initial_state, terminal_state = example\n",
    "print(f'shape of initial state (model input): {initial_state.shape}')\n",
    "print(initial_state)\n",
    "print(f'shape of terminal state (to be predicted by model): {terminal_state.shape}')\n",
    "\n",
    "body_idx = 2\n",
    "print(f'The initial x-coordinate of the body with index {body_idx} in this trajectory was {initial_state[body_idx, 1]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3ea4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell gives an example of loading a datapoint with numpy for task 2 / 3.\n",
    "\n",
    "The arrays returned by the function are structures as follows:\n",
    "initial_state: shape (n_bodies, [mass, x, y, v_x, v_y])\n",
    "remaining_trajectory: shape (n_bodies, time, [x, y, v_x, v_y])\n",
    "\n",
    "Note that for this task, you are asked to evaluate performance only with regard to the predictions of the positions (x and y).\n",
    "If you use the velocity of the remaining trajectory for training,\n",
    "this use should be purely auxiliary for the goal of predicting the positions [x,y] over time. \n",
    "While testing performance of your model on the test set, you do not have access to v_x and v_y of the remaining trajectory.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "example = load_array('data/task 2_3/train/trajectory_0.npz', task='task 2')\n",
    "\n",
    "initial_state, remaining_trajectory = example\n",
    "print(f'shape of initial state (model input): {initial_state.shape}')\n",
    "print(f'shape of terminal state (to be predicted by model): {remaining_trajectory.shape}')\n",
    "\n",
    "body_idx = 2\n",
    "time_idx = 30\n",
    "print(f'The y-coordinate of the body with index {body_idx} at time with index {time_idx} in remaining_trajectory was {remaining_trajectory[body_idx, time_idx, 1]}')\n",
    "\n",
    "test_example = load_array('data/task 2_3/test/trajectory_900.npz', task='task 3')\n",
    "test_initial_state, test_remaining_trajectory = test_example\n",
    "print(f'the shape of the input of a test data example is {test_initial_state.shape}')\n",
    "print(f'the shape of the target of a test data example is {test_remaining_trajectory.shape}')\n",
    "print(f'values of the test data example at time {time_idx}:\\n {test_remaining_trajectory[:, time_idx]}')\n",
    "print('note: velocity values are unobserved (NaNs) in the test data!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a3438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9106543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28681a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "059b633c",
   "metadata": {},
   "source": [
    "# Data Handling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6ecb529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch_geometric.data.data.Data'>\n"
     ]
    }
   ],
   "source": [
    "def create_graph_data(initial_state, terminal_state):\n",
    "    '''Takes a datapoint from task 1 data and returns a Data object ready to be used with\n",
    "    Pytorch Geometric. Each node is an object and will store initial position and speed, each edge stores\n",
    "    the distance between two objects and also their masses.'''\n",
    "    initial_state = np.array(initial_state)\n",
    "    terminal_state = np.array(terminal_state)\n",
    "\n",
    "    n_bodies = initial_state.shape[0]\n",
    "    num_features = initial_state.shape[1] - 1  # Exclude the mass from node features\n",
    "\n",
    "    # Create node features tensor\n",
    "    node_features = torch.tensor(initial_state[:, 1:], dtype=torch.float)  # Exclude the mass\n",
    "    node_features = node_features.view(-1, num_features)  # Reshape to (num_nodes, num_features)\n",
    "\n",
    "    # Create edge index tensor\n",
    "    edge_index = torch.tensor([[i, j] for i in range(n_bodies) for j in range(n_bodies) if i != j], dtype=torch.long)\n",
    "    edge_index = edge_index.t().contiguous()  # Reshape to (2, num_edges)\n",
    "\n",
    "    # Create edge features tensor\n",
    "    num_edges = edge_index.size(1)\n",
    "    edge_features = torch.empty(num_edges, 3, dtype=torch.float)  # +3 for distance and masses\n",
    "    # Populate edge features with distance and masses\n",
    "    for k, (i, j) in enumerate(edge_index.t()):\n",
    "        dx = node_features[i, 0] - node_features[j, 0]\n",
    "        dy = node_features[i, 1] - node_features[j, 1]\n",
    "        distance = torch.sqrt(dx ** 2 + dy ** 2)\n",
    "        masses = torch.from_numpy(initial_state[[i, j], 0]).float()  # Convert to PyTorch tensor\n",
    "        edge_features[k] = torch.cat((distance.view(1), masses), dim=0)\n",
    "\n",
    "    # Create target tensor\n",
    "    target = torch.tensor(terminal_state, dtype=torch.float).view(-1, 2)  # Reshape to (num_nodes, num_features + 1)\n",
    "\n",
    "    # Create PyG Data object\n",
    "    data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features, y=target)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Example usage\n",
    "initial_state = [[1.0, 0.5, 0.3, 0.2, 0.1], [2.0, 0.1, 0.4, 0.3, 0.2], [0.5, 0.7, 0.8, 0.9, 1.0]]\n",
    "terminal_state = [[0.3, 0.2], [0.4, 0.6], [0.8, 0.9]]\n",
    "\n",
    "graph_data = create_graph_data(initial_state, terminal_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8633eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data samples: 900\n"
     ]
    }
   ],
   "source": [
    "data_train_list = [] # List to store the Data objects\n",
    "\n",
    "data_folder = 'C:/Users/Gebruiker/OneDrive - TU Eindhoven/TUe/Master/2AMM10/tue-deeplearning/assignments/assignment_2/data/task 1/train'  # Specify the folder path containing the data files\n",
    "\n",
    "# Loop over all files in the folder\n",
    "for filename in os.listdir(data_folder):\n",
    "    file_path = os.path.join(data_folder, filename)\n",
    "\n",
    "    # Read the data from the file (modify this part based on your file format)\n",
    "    states = load_array(file_path, task='task 1')\n",
    "    initial_state, terminal_state = states\n",
    "\n",
    "    # Create the Data object using create_graph_data function\n",
    "    data = create_graph_data(initial_state, terminal_state)\n",
    "\n",
    "    # Append the Data object to the list\n",
    "    data_train_list.append(data)\n",
    "\n",
    "# Print the number of data samples\n",
    "print(f\"Number of data samples: {len(data_train_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a99a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "dataloader_train = DataLoader(data_train_list, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18b2874d",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66774050",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (27) must match the size of tensor b (9) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-03197854fe10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\.virtualenvs\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-03197854fe10>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_attr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\.virtualenvs\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\.virtualenvs\\venv\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;31m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         out = self.propagate(edge_index, x=x, edge_weight=edge_weight,\n\u001b[1;32m--> 186\u001b[1;33m                              size=None)\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\.virtualenvs\\venv\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    315\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m                         \u001b[0mmsg_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mmsg_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_message_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m                     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmsg_kwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\.virtualenvs\\venv\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py\u001b[0m in \u001b[0;36mmessage\u001b[1;34m(self, x_j, edge_weight)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_j\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mx_j\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0medge_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx_j\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmessage_and_aggregate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madj_t\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (27) must match the size of tensor b (9) at non-singleton dimension 0"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba598378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95154df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dea70d73",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af520ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95af5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e03ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5fb3b29",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5fa1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280031f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8240f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
