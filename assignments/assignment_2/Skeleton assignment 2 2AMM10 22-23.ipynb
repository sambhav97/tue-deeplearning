{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d32f8d18",
   "metadata": {},
   "source": [
    "# Group Details\n",
    "\n",
    "## Group Name: 12\n",
    "\n",
    "### Student 1: Denise La Gordt Dillie\n",
    "\n",
    "### Student 2: Andreea Maican\n",
    "\n",
    "### Student 3: Sambhav Jain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "faec2056",
   "metadata": {},
   "source": [
    "# Loading Data and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d0580a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T00:17:05.486823Z",
     "start_time": "2023-06-18T00:17:05.462712Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "import os\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0756591",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T00:17:05.494404Z",
     "start_time": "2023-06-18T00:17:05.466275Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_array(filename, task):\n",
    "    datapoint = np.load(filename)\n",
    "    if task == 'task 1':\n",
    "        initial_state = datapoint['initial_state']\n",
    "        terminal_state = datapoint['terminal_state']\n",
    "        return initial_state, terminal_state\n",
    "    elif task == 'task 2' or task == 'task 3':\n",
    "        whole_trajectory = datapoint['trajectory']\n",
    "        # change shape: (num_bodies, attributes, time) ->  num_bodies, time, attributes\n",
    "        whole_trajectory = np.swapaxes(whole_trajectory, 1, 2)\n",
    "        initial_state = whole_trajectory[:, 0]\n",
    "        target = whole_trajectory[:, 1:, 1:]  # drop the first timepoint (second dim) and mass (last dim) for the prediction task\n",
    "        return initial_state, target\n",
    "    else:\n",
    "        raise NotImplementedError(\"'task' argument should be 'task 1', 'task 2' or 'task 3'!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb77a4be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T00:17:05.495380Z",
     "start_time": "2023-06-18T00:17:05.468666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of initial state (model input): (8, 5)\n",
      "[[ 4.54673709 -5.27118739  5.07863417 -1.09690628 -3.66929964]\n",
      " [ 3.57509525  4.3270607  -0.08095022 -0.57868726 -2.95971243]\n",
      " [ 2.67733735 -5.15972108  5.35238208  2.42652043  1.45870728]\n",
      " [ 2.27455417 -6.79584511  2.29632123  0.30418238 -0.4065998 ]\n",
      " [ 2.38359341 -2.75861066  1.77940931 -0.07643627 -0.35954359]\n",
      " [ 4.28596268  0.34981219  4.8286224   1.35630962 -2.55760522]\n",
      " [ 3.03118516 -0.50562258 15.04631712 -0.94772523 14.98127867]\n",
      " [ 4.13530017  1.81342682  3.84375499 -0.6989711  -2.25092411]]\n",
      "shape of terminal state (to be predicted by model): (8, 2)\n",
      "The initial x-coordinate of the body with index 2 in this trajectory was -5.159721083543527\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell gives an example of loading a datapoint with numpy for task 1.\n",
    "\n",
    "The arrays returned by the function are structures as follows:\n",
    "initial_state: shape (n_bodies, [mass, x, y, v_x, v_y])\n",
    "terminal_state: shape (n_bodies, [x, y])\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "example = load_array('C:/Users/Gebruiker/OneDrive - TU Eindhoven/TUe/Master/2AMM10/tue-deeplearning/assignments/assignment_2/data/task 1/train/trajectory_0.npz', task='task 1')\n",
    "\n",
    "initial_state, terminal_state = example\n",
    "print(f'shape of initial state (model input): {initial_state.shape}')\n",
    "print(initial_state)\n",
    "print(f'shape of terminal state (to be predicted by model): {terminal_state.shape}')\n",
    "\n",
    "body_idx = 2\n",
    "print(f'The initial x-coordinate of the body with index {body_idx} in this trajectory was {initial_state[body_idx, 1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c3ea4cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T00:17:05.496914Z",
     "start_time": "2023-06-18T00:17:05.473292Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Gebruiker/OneDrive - TU Eindhoven/TUe/Master/2AMM10/tue-deeplearning/assignments/assignment_2/task 2_3/train/trajectory_0.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-233471b3b207>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \"\"\"\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mexample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/Gebruiker/OneDrive - TU Eindhoven/TUe/Master/2AMM10/tue-deeplearning/assignments/assignment_2/task 2_3/train/trajectory_0.npz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'task 2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremaining_trajectory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-6c23472e29ef>\u001b[0m in \u001b[0;36mload_array\u001b[1;34m(filename, task)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdatapoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtask\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'task 1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatapoint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'initial_state'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mterminal_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatapoint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'terminal_state'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\.virtualenvs\\venv\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Gebruiker/OneDrive - TU Eindhoven/TUe/Master/2AMM10/tue-deeplearning/assignments/assignment_2/task 2_3/train/trajectory_0.npz'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell gives an example of loading a datapoint with numpy for task 2 / 3.\n",
    "\n",
    "The arrays returned by the function are structures as follows:\n",
    "initial_state: shape (n_bodies, [mass, x, y, v_x, v_y])\n",
    "remaining_trajectory: shape (n_bodies, time, [x, y, v_x, v_y])\n",
    "\n",
    "Note that for this task, you are asked to evaluate performance only with regard to the predictions of the positions (x and y).\n",
    "If you use the velocity of the remaining trajectory for training,\n",
    "this use should be purely auxiliary for the goal of predicting the positions [x,y] over time. \n",
    "While testing performance of your model on the test set, you do not have access to v_x and v_y of the remaining trajectory.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "example = load_array('C:/Users/Gebruiker/OneDrive - TU Eindhoven/TUe/Master/2AMM10/tue-deeplearning/assignments/assignment_2/task 2_3/train/trajectory_0.npz', task='task 2')\n",
    "\n",
    "initial_state, remaining_trajectory = example\n",
    "print(f'shape of initial state (model input): {initial_state.shape}')\n",
    "print(f'shape of terminal state (to be predicted by model): {remaining_trajectory.shape}')\n",
    "\n",
    "body_idx = 2\n",
    "time_idx = 30\n",
    "print(f'The y-coordinate of the body with index {body_idx} at time with index {time_idx} in remaining_trajectory was {remaining_trajectory[body_idx, time_idx, 1]}')\n",
    "\n",
    "test_example = load_array('C:/University/master/Q4/Deep Learning/data-assignment2/data/task 2_3/test/trajectory_900.npz', task='task 3')\n",
    "test_initial_state, test_remaining_trajectory = test_example\n",
    "print(f'the shape of the input of a test data example is {test_initial_state.shape}')\n",
    "print(f'the shape of the target of a test data example is {test_remaining_trajectory.shape}')\n",
    "print(f'values of the test data example at time {time_idx}:\\n {test_remaining_trajectory[:, time_idx]}')\n",
    "print('note: velocity values are unobserved (NaNs) in the test data!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a3438a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T00:17:05.514618Z",
     "start_time": "2023-06-18T00:17:05.479020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.31455329, -4.99311363, -5.10150489,  2.2491171 , -1.82520359],\n",
       "       [ 2.58525749, -4.92574075, -4.7534334 , -4.81897728, -3.07212095],\n",
       "       [ 2.40449047,  2.23254187, -6.04595524, -0.67381217, -0.58798851],\n",
       "       [ 2.28318603,  5.6605113 , -3.76376281, -0.41268251, -1.19812499],\n",
       "       [ 4.09793595, -4.73678906, -3.94704856,  1.13634781,  4.98383634],\n",
       "       [ 4.5579536 , -0.08848969,  5.42483477,  1.460317  , -0.21585929],\n",
       "       [ 3.42356878, -4.91282501, -4.6779343 ,  0.94123905,  2.66425652],\n",
       "       [ 3.59288181, -4.48225046, -4.548729  , -2.56573061, -2.39203918]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_initial_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "059b633c",
   "metadata": {},
   "source": [
    "# Data Handling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6ecb529",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T00:17:05.514739Z",
     "start_time": "2023-06-18T00:17:05.486993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.5000, 0.3000, 0.2000, 0.1000],\n",
      "        [2.0000, 0.1000, 0.4000, 0.3000, 0.2000],\n",
      "        [0.5000, 0.7000, 0.8000, 0.9000, 1.0000]]) tensor([[0, 0, 1],\n",
      "        [1, 2, 2]]) tensor([[1.2910],\n",
      "        [   nan],\n",
      "        [   nan]]) tensor([[0.3000, 0.2000],\n",
      "        [0.4000, 0.6000],\n",
      "        [0.8000, 0.9000]])\n"
     ]
    }
   ],
   "source": [
    "def create_graph_data(initial_state, terminal_state):\n",
    "    '''Takes a datapoint from task 1 data and returns a Data object ready to be used with\n",
    "    Pytorch Geometric. Each node is an object and will store initial position and speed, each edge stores\n",
    "    the distance between two objects and also their masses.'''\n",
    "    initial_state = np.array(initial_state)\n",
    "    terminal_state = np.array(terminal_state)\n",
    "\n",
    "    n_bodies = initial_state.shape[0]\n",
    "    num_features = initial_state.shape[1]\n",
    "\n",
    "    # Create node features tensor\n",
    "    node_features = torch.tensor(initial_state, dtype=torch.float)\n",
    "    node_features = node_features.view(-1, num_features)  # Reshape to (num_nodes, num_features)\n",
    "\n",
    "    # Create edge index tensor\n",
    "    edge_index = torch.tensor([[i, j] for i in range(n_bodies) for j in range(n_bodies) if (i != j and i<j)], dtype=torch.long)\n",
    "    edge_index = edge_index.t().contiguous()  # Reshape to (2, num_edges)\n",
    "\n",
    "    # Create edge features tensor\n",
    "    num_edges = edge_index.size(1)\n",
    "    edge_features = torch.empty(num_edges, 1, dtype=torch.float) \n",
    "    # Populate edge features with force\n",
    "    for k, (i, j) in enumerate(edge_index.t()):\n",
    "        dx = node_features[i, 1] - node_features[j, 1]\n",
    "        dy = node_features[i, 2] - node_features[j, 2]\n",
    "        distance = torch.sqrt(dx * 2 + dy * 2)\n",
    "        force = ((node_features[i,0]*node_features[j,0])/(distance*2))\n",
    "        edge_features[k] = force\n",
    "\n",
    "    # Create target tensor\n",
    "    target = torch.tensor(terminal_state, dtype=torch.float).view(-1, 2)  # Reshape to (num_nodes, num_features + 1)\n",
    "\n",
    "    # Create PyG Data object\n",
    "    data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features, y=target)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Example usage\n",
    "initial_state = [[1.0, 0.5, 0.3, 0.2, 0.1], [2.0, 0.1, 0.4, 0.3, 0.2], [0.5, 0.7, 0.8, 0.9, 1.0]]\n",
    "terminal_state = [[0.3, 0.2], [0.4, 0.6], [0.8, 0.9]]\n",
    "\n",
    "graph_data = create_graph_data(initial_state, terminal_state)\n",
    "print(graph_data.x, graph_data.edge_index, graph_data.edge_attr, graph_data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9bbc8271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data samples in C:/Users/Gebruiker/OneDrive - TU Eindhoven/TUe/Master/2AMM10/tue-deeplearning/assignments/assignment_2/data/task 1/train: 900\n",
      "Number of training samples: 720\n",
      "Number of validation samples: 180\n",
      "Number of data samples in C:/Users/Gebruiker/OneDrive - TU Eindhoven/TUe/Master/2AMM10/tue-deeplearning/assignments/assignment_2/data/task 1/test: 100\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def create_dataloader(data_folder, task, shuffle, batch_size, train_ratio=0.8):\n",
    "    data_list = []  # List to store the Data objects\n",
    "\n",
    "    # Loop over all files in the folder\n",
    "    for filename in os.listdir(data_folder):\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "\n",
    "        # Read the data from the file (modify this part based on your file format)\n",
    "        states = load_array(file_path, task=task)\n",
    "        initial_state, terminal_state = states\n",
    "\n",
    "        # Create the Data object using create_graph_data function\n",
    "        data = create_graph_data(initial_state, terminal_state)\n",
    "\n",
    "        # Append the Data object to the list\n",
    "        data_list.append(data)\n",
    "\n",
    "    # Shuffle the data if specified\n",
    "    if shuffle:\n",
    "        random.shuffle(data_list)\n",
    "\n",
    "    # Calculate the number of samples\n",
    "    num_samples = len(data_list)\n",
    "\n",
    "    if \"train\" in data_folder:\n",
    "        # Calculate the number of samples for train and validation\n",
    "        num_train = int(train_ratio * num_samples)\n",
    "        num_val = num_samples - num_train\n",
    "\n",
    "        # Split the data into train and validation sets\n",
    "        train_data = data_list[:num_train]\n",
    "        val_data = data_list[num_train:]\n",
    "\n",
    "        # Print the number of data samples\n",
    "        print(f\"Number of data samples in {data_folder}: {num_samples}\")\n",
    "        print(f\"Number of training samples: {num_train}\")\n",
    "        print(f\"Number of validation samples: {num_val}\")\n",
    "\n",
    "        # Create data loaders for train and validation sets\n",
    "        dataloader_train = DataLoader(train_data, batch_size=batch_size, shuffle=shuffle)\n",
    "        dataloader_val = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        return dataloader_train, dataloader_val, data_list\n",
    "    else:\n",
    "        # Print the number of data samples\n",
    "        print(f\"Number of data samples in {data_folder}: {num_samples}\")\n",
    "\n",
    "        # Create a data loader for the data\n",
    "        dataloader = DataLoader(data_list, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "        return dataloader, data_list\n",
    "\n",
    "# Specify the paths to your train and test data folders\n",
    "data_folder_train = 'C:/Users/Gebruiker/OneDrive - TU Eindhoven/TUe/Master/2AMM10/tue-deeplearning/assignments/assignment_2/data/task 1/train'\n",
    "data_folder_test = 'C:/Users/Gebruiker/OneDrive - TU Eindhoven/TUe/Master/2AMM10/tue-deeplearning/assignments/assignment_2/data/task 1/test'\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 50\n",
    "\n",
    "# Create data loaders for train and validation sets (only if the folder contains \"train\")\n",
    "dataloader_train, dataloader_val, data_list = create_dataloader(data_folder_train, task='task 1', shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# Create a separate data loader for the test set\n",
    "dataloader_test, data_list_test = create_dataloader(data_folder_test, task='task 1', shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18b2874d",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef8b18af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(5, 64)\n",
    "        self.conv2 = GCNConv(64, 128)\n",
    "        self.conv3 = GCNConv(128, 256)\n",
    "        self.conv4 = GCNConv(256, 128)\n",
    "        self.conv5 = GCNConv(128, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5(x, edge_index)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dea70d73",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e95af5f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T00:40:04.806884Z",
     "start_time": "2023-06-18T00:40:04.801166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device='cpu'\n",
    "print(f'Loaded device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b7b4750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: 6.7285, Test Loss: 6.4098, Val Loss: 6.6983 . Training time so far: 2.1 s\n",
      "Epoch: 002, Train Loss: 6.7117, Test Loss: 6.4008, Val Loss: 6.6935 . Training time so far: 4.0 s\n",
      "Epoch: 003, Train Loss: 6.7041, Test Loss: 6.3973, Val Loss: 6.6893 . Training time so far: 6.0 s\n",
      "Epoch: 004, Train Loss: 6.6978, Test Loss: 6.3923, Val Loss: 6.6844 . Training time so far: 8.3 s\n",
      "Epoch: 005, Train Loss: 6.6925, Test Loss: 6.3884, Val Loss: 6.6876 . Training time so far: 10.4 s\n",
      "Epoch: 006, Train Loss: 6.6887, Test Loss: 6.3876, Val Loss: 6.6799 . Training time so far: 12.0 s\n",
      "Epoch: 007, Train Loss: 6.6834, Test Loss: 6.3828, Val Loss: 6.6800 . Training time so far: 13.5 s\n",
      "Epoch: 008, Train Loss: 6.6806, Test Loss: 6.3821, Val Loss: 6.6825 . Training time so far: 15.1 s\n",
      "Epoch: 009, Train Loss: 6.6770, Test Loss: 6.3798, Val Loss: 6.6783 . Training time so far: 16.6 s\n",
      "Epoch: 010, Train Loss: 6.6743, Test Loss: 6.3794, Val Loss: 6.6783 . Training time so far: 18.1 s\n",
      "Epoch: 011, Train Loss: 6.6719, Test Loss: 6.3759, Val Loss: 6.6759 . Training time so far: 19.6 s\n",
      "Epoch: 012, Train Loss: 6.6694, Test Loss: 6.3755, Val Loss: 6.6759 . Training time so far: 21.1 s\n",
      "Epoch: 013, Train Loss: 6.6669, Test Loss: 6.3744, Val Loss: 6.6759 . Training time so far: 22.5 s\n",
      "Epoch: 014, Train Loss: 6.6650, Test Loss: 6.3735, Val Loss: 6.6748 . Training time so far: 24.0 s\n",
      "Epoch: 015, Train Loss: 6.6630, Test Loss: 6.3728, Val Loss: 6.6749 . Training time so far: 25.5 s\n",
      "Epoch: 016, Train Loss: 6.6617, Test Loss: 6.3756, Val Loss: 6.6760 . Training time so far: 27.4 s\n",
      "Epoch: 017, Train Loss: 6.6591, Test Loss: 6.3716, Val Loss: 6.6721 . Training time so far: 29.6 s\n",
      "Epoch: 018, Train Loss: 6.6577, Test Loss: 6.3709, Val Loss: 6.6734 . Training time so far: 31.6 s\n",
      "Epoch: 019, Train Loss: 6.6560, Test Loss: 6.3709, Val Loss: 6.6726 . Training time so far: 33.9 s\n",
      "Epoch: 020, Train Loss: 6.6543, Test Loss: 6.3692, Val Loss: 6.6727 . Training time so far: 35.4 s\n",
      "Epoch: 021, Train Loss: 6.6528, Test Loss: 6.3696, Val Loss: 6.6697 . Training time so far: 36.8 s\n",
      "Epoch: 022, Train Loss: 6.6515, Test Loss: 6.3694, Val Loss: 6.6697 . Training time so far: 38.4 s\n",
      "Epoch: 023, Train Loss: 6.6503, Test Loss: 6.3713, Val Loss: 6.6713 . Training time so far: 40.1 s\n",
      "Epoch: 024, Train Loss: 6.6483, Test Loss: 6.3701, Val Loss: 6.6709 . Training time so far: 41.6 s\n",
      "Epoch: 025, Train Loss: 6.6467, Test Loss: 6.3683, Val Loss: 6.6724 . Training time so far: 43.1 s\n",
      "Epoch: 026, Train Loss: 6.6451, Test Loss: 6.3690, Val Loss: 6.6723 . Training time so far: 45.5 s\n",
      "Epoch: 027, Train Loss: 6.6437, Test Loss: 6.3679, Val Loss: 6.6678 . Training time so far: 47.0 s\n",
      "Epoch: 028, Train Loss: 6.6419, Test Loss: 6.3697, Val Loss: 6.6716 . Training time so far: 48.5 s\n",
      "Epoch: 029, Train Loss: 6.6406, Test Loss: 6.3693, Val Loss: 6.6715 . Training time so far: 50.0 s\n",
      "Epoch: 030, Train Loss: 6.6392, Test Loss: 6.3688, Val Loss: 6.6692 . Training time so far: 51.4 s\n",
      "Epoch: 031, Train Loss: 6.6376, Test Loss: 6.3669, Val Loss: 6.6689 . Training time so far: 52.9 s\n",
      "Epoch: 032, Train Loss: 6.6362, Test Loss: 6.3707, Val Loss: 6.6721 . Training time so far: 54.6 s\n",
      "Epoch: 033, Train Loss: 6.6352, Test Loss: 6.3677, Val Loss: 6.6667 . Training time so far: 57.1 s\n",
      "Epoch: 034, Train Loss: 6.6334, Test Loss: 6.3683, Val Loss: 6.6706 . Training time so far: 60.1 s\n",
      "Epoch: 035, Train Loss: 6.6322, Test Loss: 6.3672, Val Loss: 6.6678 . Training time so far: 61.8 s\n",
      "Epoch: 036, Train Loss: 6.6304, Test Loss: 6.3665, Val Loss: 6.6696 . Training time so far: 63.7 s\n",
      "Epoch: 037, Train Loss: 6.6298, Test Loss: 6.3708, Val Loss: 6.6693 . Training time so far: 65.3 s\n",
      "Epoch: 038, Train Loss: 6.6280, Test Loss: 6.3674, Val Loss: 6.6710 . Training time so far: 66.8 s\n",
      "Epoch: 039, Train Loss: 6.6268, Test Loss: 6.3684, Val Loss: 6.6679 . Training time so far: 71.8 s\n",
      "Epoch: 040, Train Loss: 6.6251, Test Loss: 6.3683, Val Loss: 6.6696 . Training time so far: 73.4 s\n",
      "Epoch: 041, Train Loss: 6.6246, Test Loss: 6.3661, Val Loss: 6.6680 . Training time so far: 75.1 s\n",
      "Epoch: 042, Train Loss: 6.6229, Test Loss: 6.3699, Val Loss: 6.6699 . Training time so far: 76.9 s\n",
      "Epoch: 043, Train Loss: 6.6216, Test Loss: 6.3695, Val Loss: 6.6688 . Training time so far: 81.4 s\n",
      "Epoch: 044, Train Loss: 6.6202, Test Loss: 6.3664, Val Loss: 6.6684 . Training time so far: 83.8 s\n",
      "Epoch: 045, Train Loss: 6.6184, Test Loss: 6.3704, Val Loss: 6.6664 . Training time so far: 85.7 s\n",
      "Epoch: 046, Train Loss: 6.6173, Test Loss: 6.3684, Val Loss: 6.6719 . Training time so far: 87.7 s\n",
      "Epoch: 047, Train Loss: 6.6154, Test Loss: 6.3675, Val Loss: 6.6694 . Training time so far: 90.6 s\n",
      "Epoch: 048, Train Loss: 6.6146, Test Loss: 6.3706, Val Loss: 6.6678 . Training time so far: 92.6 s\n",
      "Epoch: 049, Train Loss: 6.6132, Test Loss: 6.3665, Val Loss: 6.6685 . Training time so far: 94.1 s\n",
      "Epoch: 050, Train Loss: 6.6119, Test Loss: 6.3692, Val Loss: 6.6693 . Training time so far: 95.9 s\n"
     ]
    }
   ],
   "source": [
    "model = GNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    for data in dataloader_train:\n",
    "        data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = loss_func(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    mse = 0.0\n",
    "    total = 0\n",
    "\n",
    "    for data in loader:\n",
    "        data.to(device)\n",
    "        out = model(data)\n",
    "        if data.y is not None:  # Skip calculation if data.y is None\n",
    "            mse += F.mse_loss(out, data.y, reduction='sum').item()\n",
    "            total += data.y.size(0)\n",
    "\n",
    "    if total == 0:\n",
    "        return None  # Return None if no samples with valid labels are found\n",
    "\n",
    "    mse /= total\n",
    "    rmse = math.sqrt(mse)\n",
    "\n",
    "    return rmse\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "val_losses = []\n",
    "\n",
    "epochs = 50\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train()\n",
    "    with torch.no_grad():\n",
    "        train_loss = test(dataloader_train)\n",
    "        test_loss = test(dataloader_test)\n",
    "        val_loss = test(dataloader_val)\n",
    "    toc = time.time()\n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Val Loss: {val_loss:.4f} . Training time so far: {toc - start:.1f} s')\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d073cca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T00:40:49.239416Z",
     "start_time": "2023-06-18T00:40:49.235045Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_train(train_losses, test_losses, val_losses):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    fnt = 16\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    ax.plot(epochs, train_losses, color='blue', label='Train')\n",
    "    ax.plot(epochs, test_losses, color='green', linestyle='--', label='Test')\n",
    "    ax.plot(epochs, val_losses, color='red', linestyle='-.', label='Validation')\n",
    "    ax.legend(fontsize=fnt)\n",
    "    ax.tick_params(axis='both', labelsize=fnt)\n",
    "    ax.set_xlabel('Epoch', fontsize=fnt)\n",
    "    ax.set_ylabel('Loss', fontsize=fnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ed8a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T00:40:49.685859Z",
     "start_time": "2023-06-18T00:40:49.625673Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_train(train_losses, test_losses, val_losses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5fb3b29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T17:05:10.443904Z",
     "start_time": "2023-06-17T17:05:10.437284Z"
    }
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8ec6da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T00:40:52.763395Z",
     "start_time": "2023-06-18T00:40:52.751610Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f'Final Test accuracy: {train_losses[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 9\n",
      "Predicted = \n",
      " tensor([[ 0.2657, -0.5345],\n",
      "        [ 0.3444, -0.7377],\n",
      "        [ 0.3935, -0.8805],\n",
      "        [ 0.4297, -0.9912],\n",
      "        [ 0.4599, -1.0828],\n",
      "        [ 0.4865, -1.1614],\n",
      "        [ 0.5107, -1.2304],\n",
      "        [ 0.5331, -1.2922],\n",
      "        [ 0.5541, -1.3483]], grad_fn=<AddBackward0>),\n",
      " Ground-truth = \n",
      " tensor([[ 1.7354, -6.0871],\n",
      "        [-8.6808,  0.4488],\n",
      "        [ 0.3011, -5.7507],\n",
      "        [ 3.7730,  6.8415],\n",
      "        [-7.9975,  2.1682],\n",
      "        [ 0.8977, -6.7825],\n",
      "        [ 2.3446,  8.1104],\n",
      "        [ 5.4408,  2.4507],\n",
      "        [ 3.8509, -8.7093]])\n"
     ]
    }
   ],
   "source": [
    "def test_example(idx):\n",
    "    example = data_list_test[idx]\n",
    "    print(f'Number of objects = {example.x.shape[0]}')\n",
    "    pred = model(example)\n",
    "    true = example.y\n",
    "    print(f'Predicted = \\n {pred},\\n Ground-truth = \\n {true}')\n",
    "    \n",
    "test_example(5)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
