{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d32f8d18",
   "metadata": {},
   "source": [
    "# Group Details\n",
    "\n",
    "## Group Name: 12\n",
    "\n",
    "### Student 1: Denise La Gordt Dillie\n",
    "\n",
    "### Student 2: Andreea Maican\n",
    "\n",
    "### Student 3: Sambhav Jain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "faec2056",
   "metadata": {},
   "source": [
    "# Loading Data and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0580a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T00:17:05.486823Z",
     "start_time": "2023-06-18T00:17:05.462712Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0756591",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T00:17:05.494404Z",
     "start_time": "2023-06-18T00:17:05.466275Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_array(filename, task):\n",
    "    datapoint = np.load(filename)\n",
    "    if task == 'task 1':\n",
    "        initial_state = datapoint['initial_state']\n",
    "        terminal_state = datapoint['terminal_state']\n",
    "        return initial_state, terminal_state\n",
    "    elif task == 'task 2' or task == 'task 3':\n",
    "        whole_trajectory = datapoint['trajectory']\n",
    "        # change shape: (num_bodies, attributes, time) ->  num_bodies, time, attributes\n",
    "        whole_trajectory = np.swapaxes(whole_trajectory, 1, 2)\n",
    "        initial_state = whole_trajectory[:, 0]\n",
    "        target = whole_trajectory[:, 1:, 1:]  # drop the first timepoint (second dim) and mass (last dim) for the prediction task\n",
    "        return initial_state, target\n",
    "    else:\n",
    "        raise NotImplementedError(\"'task' argument should be 'task 1', 'task 2' or 'task 3'!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb77a4be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T00:17:05.495380Z",
     "start_time": "2023-06-18T00:17:05.468666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of initial state (model input): (8, 5)\n",
      "[[ 4.54673709 -5.27118739  5.07863417 -1.09690628 -3.66929964]\n",
      " [ 3.57509525  4.3270607  -0.08095022 -0.57868726 -2.95971243]\n",
      " [ 2.67733735 -5.15972108  5.35238208  2.42652043  1.45870728]\n",
      " [ 2.27455417 -6.79584511  2.29632123  0.30418238 -0.4065998 ]\n",
      " [ 2.38359341 -2.75861066  1.77940931 -0.07643627 -0.35954359]\n",
      " [ 4.28596268  0.34981219  4.8286224   1.35630962 -2.55760522]\n",
      " [ 3.03118516 -0.50562258 15.04631712 -0.94772523 14.98127867]\n",
      " [ 4.13530017  1.81342682  3.84375499 -0.6989711  -2.25092411]]\n",
      "shape of terminal state (to be predicted by model): (8, 2)\n",
      "The initial x-coordinate of the body with index 2 in this trajectory was -5.159721083543527\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell gives an example of loading a datapoint with numpy for task 1.\n",
    "\n",
    "The arrays returned by the function are structures as follows:\n",
    "initial_state: shape (n_bodies, [mass, x, y, v_x, v_y])\n",
    "terminal_state: shape (n_bodies, [x, y])\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "example = load_array('C:/University/master/Q4/Deep Learning/data-assignment2/data/task 1/train/trajectory_0.npz', task='task 1')\n",
    "\n",
    "initial_state, terminal_state = example\n",
    "print(f'shape of initial state (model input): {initial_state.shape}')\n",
    "print(initial_state)\n",
    "print(f'shape of terminal state (to be predicted by model): {terminal_state.shape}')\n",
    "\n",
    "body_idx = 2\n",
    "print(f'The initial x-coordinate of the body with index {body_idx} in this trajectory was {initial_state[body_idx, 1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c3ea4cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T00:17:05.496914Z",
     "start_time": "2023-06-18T00:17:05.473292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of initial state (model input): (8, 5)\n",
      "shape of terminal state (to be predicted by model): (8, 49, 4)\n",
      "The y-coordinate of the body with index 2 at time with index 30 in remaining_trajectory was -0.3861544940435097\n",
      "the shape of the input of a test data example is (8, 5)\n",
      "the shape of the target of a test data example is (8, 49, 4)\n",
      "values of the test data example at time 30:\n",
      " [[-5.85725792 -5.394571           nan         nan]\n",
      " [-6.03781257 -5.72445953         nan         nan]\n",
      " [-0.90623054 -6.93416278         nan         nan]\n",
      " [ 2.83149339 -7.50100819         nan         nan]\n",
      " [-2.85586881  1.77667501         nan         nan]\n",
      " [ 4.04424526  4.00563603         nan         nan]\n",
      " [-5.24887713 -4.83081005         nan         nan]\n",
      " [-5.81391023 -5.1109838          nan         nan]]\n",
      "note: velocity values are unobserved (NaNs) in the test data!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell gives an example of loading a datapoint with numpy for task 2 / 3.\n",
    "\n",
    "The arrays returned by the function are structures as follows:\n",
    "initial_state: shape (n_bodies, [mass, x, y, v_x, v_y])\n",
    "remaining_trajectory: shape (n_bodies, time, [x, y, v_x, v_y])\n",
    "\n",
    "Note that for this task, you are asked to evaluate performance only with regard to the predictions of the positions (x and y).\n",
    "If you use the velocity of the remaining trajectory for training,\n",
    "this use should be purely auxiliary for the goal of predicting the positions [x,y] over time. \n",
    "While testing performance of your model on the test set, you do not have access to v_x and v_y of the remaining trajectory.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "example = load_array('C:/University/master/Q4/Deep Learning/data-assignment2/data/task 2_3/train/trajectory_0.npz', task='task 2')\n",
    "\n",
    "initial_state, remaining_trajectory = example\n",
    "print(f'shape of initial state (model input): {initial_state.shape}')\n",
    "print(f'shape of terminal state (to be predicted by model): {remaining_trajectory.shape}')\n",
    "\n",
    "body_idx = 2\n",
    "time_idx = 30\n",
    "print(f'The y-coordinate of the body with index {body_idx} at time with index {time_idx} in remaining_trajectory was {remaining_trajectory[body_idx, time_idx, 1]}')\n",
    "\n",
    "test_example = load_array('C:/University/master/Q4/Deep Learning/data-assignment2/data/task 2_3/test/trajectory_900.npz', task='task 3')\n",
    "test_initial_state, test_remaining_trajectory = test_example\n",
    "print(f'the shape of the input of a test data example is {test_initial_state.shape}')\n",
    "print(f'the shape of the target of a test data example is {test_remaining_trajectory.shape}')\n",
    "print(f'values of the test data example at time {time_idx}:\\n {test_remaining_trajectory[:, time_idx]}')\n",
    "print('note: velocity values are unobserved (NaNs) in the test data!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a3438a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T00:17:05.514618Z",
     "start_time": "2023-06-18T00:17:05.479020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.31455329, -4.99311363, -5.10150489,  2.2491171 , -1.82520359],\n",
       "       [ 2.58525749, -4.92574075, -4.7534334 , -4.81897728, -3.07212095],\n",
       "       [ 2.40449047,  2.23254187, -6.04595524, -0.67381217, -0.58798851],\n",
       "       [ 2.28318603,  5.6605113 , -3.76376281, -0.41268251, -1.19812499],\n",
       "       [ 4.09793595, -4.73678906, -3.94704856,  1.13634781,  4.98383634],\n",
       "       [ 4.5579536 , -0.08848969,  5.42483477,  1.460317  , -0.21585929],\n",
       "       [ 3.42356878, -4.91282501, -4.6779343 ,  0.94123905,  2.66425652],\n",
       "       [ 3.59288181, -4.48225046, -4.548729  , -2.56573061, -2.39203918]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_initial_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "059b633c",
   "metadata": {},
   "source": [
    "# Data Handling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e6ecb529",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T00:17:05.514739Z",
     "start_time": "2023-06-18T00:17:05.486993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.5000, 0.3000, 0.2000, 0.1000],\n",
      "        [2.0000, 0.1000, 0.4000, 0.3000, 0.2000],\n",
      "        [0.5000, 0.7000, 0.8000, 0.9000, 1.0000]]) tensor([[0, 0, 1],\n",
      "        [1, 2, 2]]) tensor([[1.2910],\n",
      "        [   nan],\n",
      "        [   nan]]) tensor([[0.3000, 0.2000],\n",
      "        [0.4000, 0.6000],\n",
      "        [0.8000, 0.9000]])\n"
     ]
    }
   ],
   "source": [
    "def create_graph_data(initial_state, terminal_state):\n",
    "    '''Takes a datapoint from task 1 data and returns a Data object ready to be used with\n",
    "    Pytorch Geometric. Each node is an object and will store initial position and speed, each edge stores\n",
    "    the distance between two objects and also their masses.'''\n",
    "    initial_state = np.array(initial_state)\n",
    "    terminal_state = np.array(terminal_state)\n",
    "\n",
    "    n_bodies = initial_state.shape[0]\n",
    "    num_features = initial_state.shape[1]\n",
    "\n",
    "    # Create node features tensor\n",
    "    node_features = torch.tensor(initial_state, dtype=torch.float)\n",
    "    node_features = node_features.view(-1, num_features)  # Reshape to (num_nodes, num_features)\n",
    "\n",
    "    # Create edge index tensor\n",
    "    edge_index = torch.tensor([[i, j] for i in range(n_bodies) for j in range(n_bodies) if (i != j and i<j)], dtype=torch.long)\n",
    "    edge_index = edge_index.t().contiguous()  # Reshape to (2, num_edges)\n",
    "\n",
    "    # Create edge features tensor\n",
    "    num_edges = edge_index.size(1)\n",
    "    edge_features = torch.empty(num_edges, 1, dtype=torch.float) \n",
    "    # Populate edge features with force\n",
    "    for k, (i, j) in enumerate(edge_index.t()):\n",
    "        dx = node_features[i, 1] - node_features[j, 1]\n",
    "        dy = node_features[i, 2] - node_features[j, 2]\n",
    "        distance = torch.sqrt(dx * 2 + dy * 2)\n",
    "        force = ((node_features[i,0]*node_features[j,0])/(distance*2))\n",
    "        edge_features[k] = force\n",
    "\n",
    "    # Create target tensor\n",
    "    target = torch.tensor(terminal_state, dtype=torch.float).view(-1, 2)  # Reshape to (num_nodes, num_features + 1)\n",
    "\n",
    "    # Create PyG Data object\n",
    "    data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features, y=target)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Example usage\n",
    "initial_state = [[1.0, 0.5, 0.3, 0.2, 0.1], [2.0, 0.1, 0.4, 0.3, 0.2], [0.5, 0.7, 0.8, 0.9, 1.0]]\n",
    "terminal_state = [[0.3, 0.2], [0.4, 0.6], [0.8, 0.9]]\n",
    "\n",
    "graph_data = create_graph_data(initial_state, terminal_state)\n",
    "print(graph_data.x, graph_data.edge_index, graph_data.edge_attr, graph_data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9bbc8271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data samples in C:/University/master/Q4/Deep Learning/data-assignment2/data/task 1/train: 900\n",
      "Number of training samples: 720\n",
      "Number of validation samples: 180\n",
      "Number of data samples in C:/University/master/Q4/Deep Learning/data-assignment2/data/task 1/test: 100\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def create_dataloader(data_folder, task, shuffle, batch_size, train_ratio=0.8):\n",
    "    data_list = []  # List to store the Data objects\n",
    "\n",
    "    # Loop over all files in the folder\n",
    "    for filename in os.listdir(data_folder):\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "\n",
    "        # Read the data from the file (modify this part based on your file format)\n",
    "        states = load_array(file_path, task=task)\n",
    "        initial_state, terminal_state = states\n",
    "\n",
    "        # Create the Data object using create_graph_data function\n",
    "        data = create_graph_data(initial_state, terminal_state)\n",
    "\n",
    "        # Append the Data object to the list\n",
    "        data_list.append(data)\n",
    "\n",
    "    # Shuffle the data if specified\n",
    "    if shuffle:\n",
    "        random.shuffle(data_list)\n",
    "\n",
    "    # Calculate the number of samples\n",
    "    num_samples = len(data_list)\n",
    "\n",
    "    if \"train\" in data_folder:\n",
    "        # Calculate the number of samples for train and validation\n",
    "        num_train = int(train_ratio * num_samples)\n",
    "        num_val = num_samples - num_train\n",
    "\n",
    "        # Split the data into train and validation sets\n",
    "        train_data = data_list[:num_train]\n",
    "        val_data = data_list[num_train:]\n",
    "\n",
    "        # Print the number of data samples\n",
    "        print(f\"Number of data samples in {data_folder}: {num_samples}\")\n",
    "        print(f\"Number of training samples: {num_train}\")\n",
    "        print(f\"Number of validation samples: {num_val}\")\n",
    "\n",
    "        # Create data loaders for train and validation sets\n",
    "        dataloader_train = DataLoader(train_data, batch_size=batch_size, shuffle=shuffle)\n",
    "        dataloader_val = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        return dataloader_train, dataloader_val\n",
    "    else:\n",
    "        # Print the number of data samples\n",
    "        print(f\"Number of data samples in {data_folder}: {num_samples}\")\n",
    "\n",
    "        # Create a data loader for the data\n",
    "        dataloader = DataLoader(data_list, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "        return dataloader\n",
    "\n",
    "# Specify the paths to your train and test data folders\n",
    "data_folder_train = 'C:/University/master/Q4/Deep Learning/data-assignment2/data/task 1/train'\n",
    "data_folder_test = 'C:/University/master/Q4/Deep Learning/data-assignment2/data/task 1/test'\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 50\n",
    "\n",
    "# Create data loaders for train and validation sets (only if the folder contains \"train\")\n",
    "dataloader_train, dataloader_val = create_dataloader(data_folder_train, task='task 1', shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# Create a separate data loader for the test set\n",
    "dataloader_test= create_dataloader(data_folder_test, task='task 1', shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18b2874d",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef8b18af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dea70d73",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e95af5f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T00:40:04.806884Z",
     "start_time": "2023-06-18T00:40:04.801166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device='cpu'\n",
    "print(f'Loaded device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7b7b4750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: 6.8185, Test Loss: 6.4203, Val Loss: 6.4649 . Training time so far: 0.6 s\n",
      "Epoch: 002, Train Loss: 6.7914, Test Loss: 6.4064, Val Loss: 6.4254 . Training time so far: 1.1 s\n",
      "Epoch: 003, Train Loss: 6.7828, Test Loss: 6.4079, Val Loss: 6.4163 . Training time so far: 1.5 s\n",
      "Epoch: 004, Train Loss: 6.7766, Test Loss: 6.4000, Val Loss: 6.4050 . Training time so far: 1.9 s\n",
      "Epoch: 005, Train Loss: 6.7726, Test Loss: 6.3961, Val Loss: 6.4021 . Training time so far: 2.3 s\n",
      "Epoch: 006, Train Loss: 6.7689, Test Loss: 6.3918, Val Loss: 6.3971 . Training time so far: 2.7 s\n",
      "Epoch: 007, Train Loss: 6.7651, Test Loss: 6.3885, Val Loss: 6.3966 . Training time so far: 3.2 s\n",
      "Epoch: 008, Train Loss: 6.7616, Test Loss: 6.3896, Val Loss: 6.3959 . Training time so far: 3.6 s\n",
      "Epoch: 009, Train Loss: 6.7580, Test Loss: 6.3838, Val Loss: 6.3889 . Training time so far: 4.0 s\n",
      "Epoch: 010, Train Loss: 6.7549, Test Loss: 6.3845, Val Loss: 6.3886 . Training time so far: 4.4 s\n",
      "Epoch: 011, Train Loss: 6.7520, Test Loss: 6.3829, Val Loss: 6.3888 . Training time so far: 4.9 s\n",
      "Epoch: 012, Train Loss: 6.7495, Test Loss: 6.3806, Val Loss: 6.3882 . Training time so far: 5.3 s\n",
      "Epoch: 013, Train Loss: 6.7467, Test Loss: 6.3792, Val Loss: 6.3872 . Training time so far: 5.7 s\n",
      "Epoch: 014, Train Loss: 6.7439, Test Loss: 6.3773, Val Loss: 6.3816 . Training time so far: 6.1 s\n",
      "Epoch: 015, Train Loss: 6.7413, Test Loss: 6.3747, Val Loss: 6.3831 . Training time so far: 6.5 s\n",
      "Epoch: 016, Train Loss: 6.7389, Test Loss: 6.3732, Val Loss: 6.3853 . Training time so far: 6.9 s\n",
      "Epoch: 017, Train Loss: 6.7365, Test Loss: 6.3744, Val Loss: 6.3832 . Training time so far: 7.3 s\n",
      "Epoch: 018, Train Loss: 6.7344, Test Loss: 6.3732, Val Loss: 6.3805 . Training time so far: 7.8 s\n",
      "Epoch: 019, Train Loss: 6.7329, Test Loss: 6.3758, Val Loss: 6.3819 . Training time so far: 8.2 s\n",
      "Epoch: 020, Train Loss: 6.7305, Test Loss: 6.3719, Val Loss: 6.3794 . Training time so far: 8.6 s\n",
      "Epoch: 021, Train Loss: 6.7291, Test Loss: 6.3700, Val Loss: 6.3839 . Training time so far: 9.0 s\n",
      "Epoch: 022, Train Loss: 6.7273, Test Loss: 6.3745, Val Loss: 6.3827 . Training time so far: 9.5 s\n",
      "Epoch: 023, Train Loss: 6.7254, Test Loss: 6.3713, Val Loss: 6.3802 . Training time so far: 9.9 s\n",
      "Epoch: 024, Train Loss: 6.7232, Test Loss: 6.3708, Val Loss: 6.3826 . Training time so far: 10.4 s\n",
      "Epoch: 025, Train Loss: 6.7212, Test Loss: 6.3717, Val Loss: 6.3811 . Training time so far: 10.8 s\n",
      "Epoch: 026, Train Loss: 6.7201, Test Loss: 6.3692, Val Loss: 6.3813 . Training time so far: 11.2 s\n",
      "Epoch: 027, Train Loss: 6.7180, Test Loss: 6.3722, Val Loss: 6.3816 . Training time so far: 11.7 s\n",
      "Epoch: 028, Train Loss: 6.7164, Test Loss: 6.3719, Val Loss: 6.3786 . Training time so far: 12.2 s\n",
      "Epoch: 029, Train Loss: 6.7149, Test Loss: 6.3736, Val Loss: 6.3827 . Training time so far: 12.6 s\n",
      "Epoch: 030, Train Loss: 6.7132, Test Loss: 6.3733, Val Loss: 6.3770 . Training time so far: 13.0 s\n",
      "Epoch: 031, Train Loss: 6.7116, Test Loss: 6.3714, Val Loss: 6.3827 . Training time so far: 13.5 s\n",
      "Epoch: 032, Train Loss: 6.7106, Test Loss: 6.3722, Val Loss: 6.3845 . Training time so far: 14.0 s\n",
      "Epoch: 033, Train Loss: 6.7089, Test Loss: 6.3739, Val Loss: 6.3798 . Training time so far: 14.4 s\n",
      "Epoch: 034, Train Loss: 6.7076, Test Loss: 6.3753, Val Loss: 6.3859 . Training time so far: 14.8 s\n",
      "Epoch: 035, Train Loss: 6.7056, Test Loss: 6.3739, Val Loss: 6.3814 . Training time so far: 15.3 s\n",
      "Epoch: 036, Train Loss: 6.7040, Test Loss: 6.3737, Val Loss: 6.3804 . Training time so far: 15.7 s\n",
      "Epoch: 037, Train Loss: 6.7026, Test Loss: 6.3738, Val Loss: 6.3791 . Training time so far: 16.2 s\n",
      "Epoch: 038, Train Loss: 6.7017, Test Loss: 6.3752, Val Loss: 6.3809 . Training time so far: 16.6 s\n",
      "Epoch: 039, Train Loss: 6.7002, Test Loss: 6.3768, Val Loss: 6.3830 . Training time so far: 17.0 s\n",
      "Epoch: 040, Train Loss: 6.6987, Test Loss: 6.3731, Val Loss: 6.3832 . Training time so far: 17.5 s\n",
      "Epoch: 041, Train Loss: 6.6975, Test Loss: 6.3769, Val Loss: 6.3814 . Training time so far: 17.9 s\n",
      "Epoch: 042, Train Loss: 6.6961, Test Loss: 6.3781, Val Loss: 6.3804 . Training time so far: 18.4 s\n",
      "Epoch: 043, Train Loss: 6.6946, Test Loss: 6.3746, Val Loss: 6.3841 . Training time so far: 18.9 s\n",
      "Epoch: 044, Train Loss: 6.6932, Test Loss: 6.3790, Val Loss: 6.3826 . Training time so far: 19.3 s\n",
      "Epoch: 045, Train Loss: 6.6921, Test Loss: 6.3792, Val Loss: 6.3832 . Training time so far: 19.7 s\n",
      "Epoch: 046, Train Loss: 6.6914, Test Loss: 6.3748, Val Loss: 6.3795 . Training time so far: 20.1 s\n",
      "Epoch: 047, Train Loss: 6.6895, Test Loss: 6.3798, Val Loss: 6.3868 . Training time so far: 20.5 s\n",
      "Epoch: 048, Train Loss: 6.6880, Test Loss: 6.3787, Val Loss: 6.3811 . Training time so far: 21.0 s\n",
      "Epoch: 049, Train Loss: 6.6870, Test Loss: 6.3765, Val Loss: 6.3811 . Training time so far: 21.4 s\n",
      "Epoch: 050, Train Loss: 6.6863, Test Loss: 6.3819, Val Loss: 6.3834 . Training time so far: 21.8 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "# class GNN(torch.nn.Module):\n",
    "#     def __init__(self, hidden_dim=64):\n",
    "#         super(GNN, self).__init__()\n",
    "#         self.conv1 = GCNConv(4, hidden_dim) \n",
    "#         self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "#         # self.lstm = torch.nn.LSTM(hidden_dim, hidden_dim)\n",
    "#         self.lin = torch.nn.Linear(hidden_dim, 2) \n",
    "\n",
    "#     def forward(self, data):\n",
    "#         x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "#         h = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "#         h = F.relu(self.conv2(h, edge_index, edge_attr))\n",
    "#         # h = h.unsqueeze(0)\n",
    "#         # _, (h_n, _) = self.lstm(h)\n",
    "#         out = self.lin(h)\n",
    "#         return out\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(5, 64)\n",
    "        self.conv2 = GCNConv(64, 128)\n",
    "        self.conv3 = GCNConv(128, 256)\n",
    "        self.conv4 = GCNConv(256, 128)\n",
    "        self.conv5 = GCNConv(128, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5(x, edge_index)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# model = GNNModel(num_features=4, hidden_dim=64, num_classes=2).to(device)\n",
    "\n",
    "model = GNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    for data in dataloader_train:\n",
    "        data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = loss_func(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    mse = 0.0\n",
    "    total = 0\n",
    "\n",
    "    for data in loader:\n",
    "        data.to(device)\n",
    "        out = model(data)\n",
    "        if data.y is not None:  # Skip calculation if data.y is None\n",
    "            mse += F.mse_loss(out, data.y, reduction='sum').item()\n",
    "            total += data.y.size(0)\n",
    "\n",
    "    if total == 0:\n",
    "        return None  # Return None if no samples with valid labels are found\n",
    "\n",
    "    mse /= total\n",
    "    rmse = math.sqrt(mse)\n",
    "\n",
    "    return rmse\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "val_losses = []\n",
    "\n",
    "epochs = 50\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train()\n",
    "    with torch.no_grad():\n",
    "        train_loss = test(dataloader_train)\n",
    "        test_loss = test(dataloader_test)\n",
    "        val_loss = test(dataloader_val)\n",
    "    toc = time.time()\n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Val Loss: {val_loss:.4f} . Training time so far: {toc - start:.1f} s')\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "11ab5700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Loss: 6.7892, Test Loss: 6.4481, Val Loss: 6.7635 . Training time so far: 0.5 s\n",
      "Epoch: 002, Train Loss: 6.7859, Test Loss: 6.4445, Val Loss: 6.7599 . Training time so far: 0.9 s\n",
      "Epoch: 003, Train Loss: 6.7843, Test Loss: 6.4428, Val Loss: 6.7596 . Training time so far: 1.4 s\n",
      "Epoch: 004, Train Loss: 6.7857, Test Loss: 6.4371, Val Loss: 6.7574 . Training time so far: 1.9 s\n",
      "Epoch: 005, Train Loss: 6.7842, Test Loss: 6.4360, Val Loss: 6.7575 . Training time so far: 2.4 s\n",
      "Epoch: 006, Train Loss: 6.7838, Test Loss: 6.4416, Val Loss: 6.7604 . Training time so far: 2.8 s\n",
      "Epoch: 007, Train Loss: 6.7852, Test Loss: 6.4408, Val Loss: 6.7596 . Training time so far: 3.3 s\n",
      "Epoch: 008, Train Loss: 6.7835, Test Loss: 6.4365, Val Loss: 6.7591 . Training time so far: 3.7 s\n",
      "Epoch: 009, Train Loss: 6.7853, Test Loss: 6.4377, Val Loss: 6.7584 . Training time so far: 4.1 s\n",
      "Epoch: 010, Train Loss: 6.7857, Test Loss: 6.4411, Val Loss: 6.7595 . Training time so far: 4.6 s\n",
      "Epoch: 011, Train Loss: 6.7859, Test Loss: 6.4333, Val Loss: 6.7575 . Training time so far: 5.0 s\n",
      "Epoch: 012, Train Loss: 6.7839, Test Loss: 6.4368, Val Loss: 6.7585 . Training time so far: 5.5 s\n",
      "Epoch: 013, Train Loss: 6.7856, Test Loss: 6.4334, Val Loss: 6.7575 . Training time so far: 5.9 s\n",
      "Epoch: 014, Train Loss: 6.7841, Test Loss: 6.4359, Val Loss: 6.7578 . Training time so far: 6.3 s\n",
      "Epoch: 015, Train Loss: 6.7831, Test Loss: 6.4421, Val Loss: 6.7617 . Training time so far: 6.8 s\n",
      "Epoch: 016, Train Loss: 6.7865, Test Loss: 6.4409, Val Loss: 6.7608 . Training time so far: 7.2 s\n",
      "Epoch: 017, Train Loss: 6.7872, Test Loss: 6.4336, Val Loss: 6.7574 . Training time so far: 7.6 s\n",
      "Epoch: 018, Train Loss: 6.7900, Test Loss: 6.4311, Val Loss: 6.7587 . Training time so far: 8.0 s\n",
      "Epoch: 019, Train Loss: 6.7832, Test Loss: 6.4337, Val Loss: 6.7578 . Training time so far: 8.4 s\n",
      "Epoch: 020, Train Loss: 6.7849, Test Loss: 6.4432, Val Loss: 6.7610 . Training time so far: 8.9 s\n",
      "Epoch: 021, Train Loss: 6.7834, Test Loss: 6.4391, Val Loss: 6.7597 . Training time so far: 9.3 s\n",
      "Epoch: 022, Train Loss: 6.7853, Test Loss: 6.4370, Val Loss: 6.7602 . Training time so far: 9.8 s\n",
      "Epoch: 023, Train Loss: 6.7853, Test Loss: 6.4325, Val Loss: 6.7582 . Training time so far: 10.2 s\n",
      "Epoch: 024, Train Loss: 6.7846, Test Loss: 6.4380, Val Loss: 6.7586 . Training time so far: 10.6 s\n",
      "Epoch: 025, Train Loss: 6.7851, Test Loss: 6.4404, Val Loss: 6.7606 . Training time so far: 11.1 s\n",
      "Epoch: 026, Train Loss: 6.7850, Test Loss: 6.4384, Val Loss: 6.7593 . Training time so far: 11.5 s\n",
      "Epoch: 027, Train Loss: 6.7883, Test Loss: 6.4416, Val Loss: 6.7599 . Training time so far: 11.9 s\n",
      "Epoch: 028, Train Loss: 6.7842, Test Loss: 6.4363, Val Loss: 6.7574 . Training time so far: 12.4 s\n",
      "Epoch: 029, Train Loss: 6.7836, Test Loss: 6.4348, Val Loss: 6.7573 . Training time so far: 12.8 s\n",
      "Epoch: 030, Train Loss: 6.7839, Test Loss: 6.4334, Val Loss: 6.7577 . Training time so far: 13.2 s\n",
      "Epoch: 031, Train Loss: 6.7835, Test Loss: 6.4347, Val Loss: 6.7579 . Training time so far: 13.7 s\n",
      "Epoch: 032, Train Loss: 6.7846, Test Loss: 6.4382, Val Loss: 6.7587 . Training time so far: 14.1 s\n",
      "Epoch: 033, Train Loss: 6.7847, Test Loss: 6.4391, Val Loss: 6.7593 . Training time so far: 14.6 s\n",
      "Epoch: 034, Train Loss: 6.7868, Test Loss: 6.4415, Val Loss: 6.7627 . Training time so far: 15.0 s\n",
      "Epoch: 035, Train Loss: 6.7839, Test Loss: 6.4365, Val Loss: 6.7583 . Training time so far: 15.5 s\n",
      "Epoch: 036, Train Loss: 6.7838, Test Loss: 6.4343, Val Loss: 6.7574 . Training time so far: 15.9 s\n",
      "Epoch: 037, Train Loss: 6.7840, Test Loss: 6.4330, Val Loss: 6.7574 . Training time so far: 16.3 s\n",
      "Epoch: 038, Train Loss: 6.7863, Test Loss: 6.4404, Val Loss: 6.7597 . Training time so far: 16.8 s\n",
      "Epoch: 039, Train Loss: 6.7839, Test Loss: 6.4371, Val Loss: 6.7586 . Training time so far: 17.2 s\n",
      "Epoch: 040, Train Loss: 6.7838, Test Loss: 6.4392, Val Loss: 6.7594 . Training time so far: 17.6 s\n",
      "Epoch: 041, Train Loss: 6.7846, Test Loss: 6.4354, Val Loss: 6.7580 . Training time so far: 18.1 s\n",
      "Epoch: 042, Train Loss: 6.7839, Test Loss: 6.4373, Val Loss: 6.7589 . Training time so far: 18.5 s\n",
      "Epoch: 043, Train Loss: 6.7841, Test Loss: 6.4366, Val Loss: 6.7596 . Training time so far: 18.9 s\n",
      "Epoch: 044, Train Loss: 6.7837, Test Loss: 6.4365, Val Loss: 6.7582 . Training time so far: 19.3 s\n",
      "Epoch: 045, Train Loss: 6.7855, Test Loss: 6.4332, Val Loss: 6.7574 . Training time so far: 19.8 s\n",
      "Epoch: 046, Train Loss: 6.7846, Test Loss: 6.4333, Val Loss: 6.7593 . Training time so far: 20.2 s\n",
      "Epoch: 047, Train Loss: 6.7865, Test Loss: 6.4306, Val Loss: 6.7590 . Training time so far: 20.6 s\n",
      "Epoch: 048, Train Loss: 6.7846, Test Loss: 6.4331, Val Loss: 6.7578 . Training time so far: 21.0 s\n",
      "Epoch: 049, Train Loss: 6.7842, Test Loss: 6.4379, Val Loss: 6.7596 . Training time so far: 21.5 s\n",
      "Epoch: 050, Train Loss: 6.7846, Test Loss: 6.4385, Val Loss: 6.7587 . Training time so far: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "# import torch.nn.functional as F\n",
    "# import math\n",
    "\n",
    "\n",
    "# model = MpGNN(node_feat_dim=4, hidden_dim=32, num_layers=10)\n",
    "# model.to(device)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr= 0.009)\n",
    "# loss_func = torch.nn.MSELoss()\n",
    "\n",
    "# def train():\n",
    "#     model.train()\n",
    "#     for data in dataloader_train:\n",
    "#         data.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         out = model(data.x, data.edge_index, data.batch)\n",
    "#         loss = loss_func(out, data.y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "        \n",
    "# def test(loader):\n",
    "#     model.eval()\n",
    "#     mse = 0.0\n",
    "#     total = 0\n",
    "\n",
    "#     for data in loader:\n",
    "#         data.to(device)\n",
    "#         out = model(data.x, data.edge_index, data.batch)\n",
    "#         mse += F.mse_loss(out, data.y, reduction='sum').item()\n",
    "#         total += data.y.size(0)\n",
    "\n",
    "#     mse /= total\n",
    "#     rmse = math.sqrt(mse)\n",
    "\n",
    "#     return rmse\n",
    "\n",
    "# train_losses = []\n",
    "# test_losses = []\n",
    "# val_losses = []\n",
    "\n",
    "# epochs = 50\n",
    "# start = time.time()\n",
    "\n",
    "# for epoch in range(1, epochs + 1):\n",
    "#     train()\n",
    "#     with torch.no_grad():\n",
    "#         train_loss = test(dataloader_train)\n",
    "#         test_loss = test(dataloader_test)\n",
    "#         val_loss = test(dataloader_val)\n",
    "#     toc = time.time()\n",
    "#     print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Val Loss: {val_loss:.4f} . Training time so far: {toc - start:.1f} s')\n",
    "#     train_losses.append(train_loss)\n",
    "#     test_losses.append(test_loss)\n",
    "#     val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d073cca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T00:40:49.239416Z",
     "start_time": "2023-06-18T00:40:49.235045Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_train(train_losses, test_losses, val_losses):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    fnt = 16\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    ax.plot(epochs, train_losses, color='blue', label='Train')\n",
    "    ax.plot(epochs, test_losses, color='green', linestyle='--', label='Test')\n",
    "    ax.plot(epochs, val_losses, color='red', linestyle='-.', label='Validation')\n",
    "    ax.legend(fontsize=fnt)\n",
    "    ax.tick_params(axis='both', labelsize=fnt)\n",
    "    ax.set_xlabel('Epoch', fontsize=fnt)\n",
    "    ax.set_ylabel('Loss', fontsize=fnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ed8a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T00:40:49.685859Z",
     "start_time": "2023-06-18T00:40:49.625673Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_train(train_losses, test_losses, val_losses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5fb3b29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T17:05:10.443904Z",
     "start_time": "2023-06-17T17:05:10.437284Z"
    }
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8ec6da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T00:40:52.763395Z",
     "start_time": "2023-06-18T00:40:52.751610Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f'Final Test accuracy: {train_losses[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
